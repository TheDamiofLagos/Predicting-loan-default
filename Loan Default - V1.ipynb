{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv(r\"/workspaces/Predicting-loan-default/Loan_default.csv\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Overview: The dataset contains 255,347 entries and 18 columns. The target variable is 'Default', which is binary (0 or 1).\n",
    "\n",
    "Missing Values: There are no missing values in the dataset, which simplifies the preprocessing step.\n",
    "\n",
    "Data Types: Most of the features are numeric (int64 or float64), but there are several categorical features ('Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner') that need to be encoded before they can be used in a machine learning model.\n",
    "\n",
    "Feature Distribution: The 'describe()' method provides a summary of the numeric features. It's important to look at the mean, standard deviation, and the range (min and max) to get a sense of the distribution and scale of each feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing irrelevant features: Drop the LoanID column\n",
    "# the LoanID column seems to be a unique identifier for each loan and is unlikely to have predictive power, so we can consider dropping it.\n",
    "df = df.drop('LoanID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that are highly correlated with each other can be considered redundant. \n",
    "# For example, if two features provide very similar information, you might choose to keep only one of them. \n",
    "# At this stage, we can look at the correlation matrix to identify any potential redundant features.\n",
    "\n",
    "# Select numerical features\n",
    "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "\n",
    "# RUNNING CORRELATION ANALYSIS\n",
    "# Plot the correlation matrix for numerical features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df[numerical_features].corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age and Default: There is a moderate negative correlation (-0.167783) between Age and Default. This suggests that older borrowers are less likely to default on their loans.\n",
    "# Income and Default: There is a negative correlation (-0.099119) between Income and Default, indicating that borrowers with higher incomes are less likely to default.\n",
    "# LoanAmount and Default: There is a positive correlation (0.086659) between LoanAmount and Default, suggesting that higher loan amounts are associated with a higher likelihood of default.\n",
    "# CreditScore and Default: There is a negative correlation (-0.034166) between CreditScore and Default, which is expected as higher credit scores are typically associated with lower default rates. (based on domain knowledge)\n",
    "# MonthsEmployed and Default: There is a negative correlation (-0.097374) between MonthsEmployed and Default, indicating that borrowers with longer employment history are less likely to default.\n",
    "# InterestRate and Default: There is a positive correlation (0.131273) between InterestRate and Default, suggesting that higher interest rates are associated with a higher likelihood of default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only captures linear relationships and might not detect non-linear relationships. \n",
    "# It also doesn't take into account the interactions between features or the combined effect of multiple features on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check for important features, an alternative is to use Feature Importance from Tree-based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Default', axis=1)\n",
    "y = df['Default']\n",
    "\n",
    "# Define the preprocessor with one-hot encoding for categorical variables\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "# Apply the preprocessing\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "importances = rf.feature_importances_\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importance\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the feature importance scores from the Random Forest model, we can see that the most important features for predicting loan defaults are:\n",
    "\n",
    "# Income: This is the most important feature, which aligns with the intuition that a borrower's income is a crucial factor in their ability to repay a loan.\n",
    "# Interest Rate: The interest rate of the loan is also highly important, suggesting that higher interest rates might be associated with a higher likelihood of default.\n",
    "# Loan Amount: The amount of the loan is another key factor, which makes sense as larger loans might be harder to repay.\n",
    "# Age: The borrower's age is also important, potentially reflecting different financial stability levels at different life stages.\n",
    "# Credit Score: As expected, the borrower's credit score is a significant predictor, with higher scores indicating lower risk of default.\n",
    "# Months Employed: The length of employment is also important, likely reflecting the borrower's job stability and income security.\n",
    "# DTIRatio (Debt-to-Income Ratio): This is another critical factor, indicating the borrower's ability to manage loan repayments relative to their income.\n",
    "# The categorical features, such as HasMortgage, MaritalStatus, and Education, have lower importance scores compared to the numerical features. \n",
    "# However, they still contribute to the model's predictive power and should not be disregarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets look at Categorical specifically\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Define a function to plot the distribution of the target variable by category\n",
    "def plot_target_distribution_by_category(df, feature, target):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x=feature, hue=target, data=df)\n",
    "    plt.title(f'Distribution of {target} by {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "# Define a function to perform a chi-squared test for independence\n",
    "def chi_squared_test(df, feature, target):\n",
    "    contingency_table = pd.crosstab(df[feature], df[target])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    print(f'Chi-squared test for {feature} and {target}:')\n",
    "    print(f'Chi-squared statistic: {chi2}')\n",
    "    print(f'p-value: {p}\\n')\n",
    "\n",
    "# List of categorical features\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Analyze each categorical feature\n",
    "for feature in categorical_features:\n",
    "    plot_target_distribution_by_category(df, feature, 'Default')\n",
    "    chi_squared_test(df, feature, 'Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For numerical features, we selected the below:\n",
    "Income\n",
    "InterestRate\n",
    "LoanAmount\n",
    "Age\n",
    "CreditScore\n",
    "MonthsEmployed\n",
    "DTIRatio\n",
    "\n",
    "For categoricals, we selected\n",
    "Education\n",
    "EmploymentType\n",
    "MaritalStatus\n",
    "HasMortgage\n",
    "HasDependents\n",
    "LoanPurpose\n",
    "HasCoSigner\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
